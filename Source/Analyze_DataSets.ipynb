{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as path\n",
    "import math\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"Spanish\"\n",
    "dictionary_name = \"WordNet\"\n",
    "language_code = \"es\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI_DATASET_DIR_INPUT = f\"/home/akabiri/arman.kabiri94@gmail.com/NLP_Stuff/DefinitionModeling_Datasets--IG--/{language}/{dictionary_name}/ReadyToUse\"\n",
    "URI_EMBEDDINGS_W2V_FILE_INPUT = f\"/home/akabiri/arman.kabiri94@gmail.com/NLP_Stuff/Embeddings--IG--/Word2vec/FastTextPreProcessingOnWikipedia/ToUse/wiki-w2v.{language_code.lower()}.txt\"\n",
    "URI_EMBEDDINGS_ADAGRAM_FILE_INPUT = f\"/home/akabiri/arman.kabiri94@gmail.com/NLP_Stuff/Embeddings--IG--/AdaGram-juliaV4/Embeddings/Multilingual/ToUse/AdaGram-{language_code.upper()}-win10-proto30-min20-300D-0.15-SS1e-5-STe1-17-Epoch1.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, validset, testset = dict(), dict(), dict()\n",
    "entire_dataset = dict()\n",
    "dataset = {'entire' : entire_dataset, 'train' : trainset, 'valid' : validset, 'test' : testset}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab_w2v=set()\n",
    "with open(URI_EMBEDDINGS_W2V_FILE_INPUT) as file:\n",
    "    for line in file:\n",
    "        word = line.strip().split(' ')[0]\n",
    "        vocab_w2v.add(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vocab_adagram=set()\n",
    "with open(URI_EMBEDDINGS_ADAGRAM_FILE_INPUT) as file:\n",
    "    for line in file:\n",
    "        word = line.strip().split(' ')[0]\n",
    "        vocab_adagram.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, set_i in dataset.items():\n",
    "    if filename!='entire':\n",
    "        with open(path.join(URI_DATASET_DIR_INPUT,filename + '.txt')) as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split('\\t')\n",
    "                word, definition = parts[0],parts[3]\n",
    "                if word in set_i:\n",
    "                    set_i[word].append(definition)\n",
    "                else:\n",
    "                    set_i[word] = [definition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_dataset.update(dataset['train'])\n",
    "entire_dataset.update(dataset['valid'])\n",
    "entire_dataset.update(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15148\n",
      "18934\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset['train']))\n",
    "print(len(entire_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(vocab_w2v), len(vocab_adagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: Spanish, Dictionary name: WordNet\n",
      "\n",
      "Number of words:\n",
      "\n",
      "Number of words of entire is: 18934.\n",
      "Number of words of train is: 15148.\n",
      "Number of words of valid is: 1893.\n",
      "Number of words of test is: 1893.\n",
      "\n",
      "\n",
      "Mean and Variance:\n",
      "\n",
      "entire:\n",
      "\n",
      "Portion of words with more than one definition in entire is:0.12987218759902822\n",
      "\n",
      "Average of number of definitions per word in entire is 1.2135312136896588.\n",
      "Variance of number of definitions per word in entire is 0.7167217716712994.\n",
      "\n",
      "Min of number of definitions per word in entire is 1.\n",
      "Max of number of definitions per word in entire is 28.\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "train:\n",
      "\n",
      "Portion of words with more than one definition in train is:0.1290599419065223\n",
      "\n",
      "Average of number of definitions per word in train is 1.212305254819118.\n",
      "Variance of number of definitions per word in train is 0.7010778570345096.\n",
      "\n",
      "Min of number of definitions per word in train is 1.\n",
      "Max of number of definitions per word in train is 28.\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "valid:\n",
      "\n",
      "Portion of words with more than one definition in valid is:0.12995245641838352\n",
      "\n",
      "Average of number of definitions per word in valid is 1.2044374009508716.\n",
      "Variance of number of definitions per word in valid is 0.716639918515863.\n",
      "\n",
      "Min of number of definitions per word in valid is 1.\n",
      "Max of number of definitions per word in valid is 26.\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "test:\n",
      "\n",
      "Portion of words with more than one definition in test is:0.13629160063391443\n",
      "\n",
      "Average of number of definitions per word in test is 1.2324352879027998.\n",
      "Variance of number of definitions per word in test is 0.8423512015448034.\n",
      "\n",
      "Min of number of definitions per word in test is 1.\n",
      "Max of number of definitions per word in test is 26.\n",
      "\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Language: {language}, Dictionary name: {dictionary_name}\\n\")\n",
    "\n",
    "print('Number of words:\\n')\n",
    "for filename, set_i in dataset.items():\n",
    "    \n",
    "    definitions_num = []\n",
    "    for word, deflist in set_i.items():\n",
    "        definitions_num.append(len(deflist))\n",
    "   \n",
    "    print(f\"Number of words of {filename} is: {len(set_i)}.\")\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "print('Mean and Variance:\\n')\n",
    "for filename, set_i in dataset.items():\n",
    "    \n",
    "    definitions_num = []\n",
    "    for word, deflist in set_i.items():\n",
    "        definitions_num.append(len(deflist))\n",
    "    \n",
    "    print(filename+\":\\n\")\n",
    "    print(f\"Portion of words with more than one definition in {filename} is:\"\n",
    "          f\"{sum(map(lambda x : x > 1, definitions_num)) / len(definitions_num)}\\n\")\n",
    "    print(f\"Average of number of definitions per word in {filename} is {statistics.mean(definitions_num)}.\")\n",
    "    print(f\"Variance of number of definitions per word in {filename} is {statistics.variance(definitions_num)}.\\n\")  \n",
    "    print(f\"Min of number of definitions per word in {filename} is {min(definitions_num)}.\")\n",
    "    print(f\"Max of number of definitions per word in {filename} is {max(definitions_num)}.\")\n",
    "    print('\\n')\n",
    "    \n",
    "    # Calculating OOVs:\n",
    "#    set_i_vocab = set()\n",
    "#    for word, deflist in set_i.items():\n",
    "#        for defitem in deflist:\n",
    "#            set_i_vocab.update(defitem.split(' '))\n",
    "#    \n",
    "#    intersection_w2v = vocab_w2v.intersection(set_i_vocab)\n",
    "#    intersection_adagram = vocab_adagram.intersection(set_i_vocab)\n",
    "#    print(f\"Portion of OOVs in {filename} wrt W2V is {(len(set_i_vocab)-len(intersection_w2v))/len(set_i_vocab)}\")\n",
    "#    print(f\"Portion of OOVs in {filename} wrt Adagram is {(len(set_i_vocab)-len(intersection_adagram))/len(set_i_vocab)}\")\n",
    "        \n",
    "    print('\\n------------------------------------\\n')\n",
    "    \n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'set_i_vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cd02d618faee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_i_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'set_i_vocab' is not defined"
     ]
    }
   ],
   "source": [
    "len(set_i_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(intersection_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_i_vocab.difference(intersection_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7.5",
   "language": "python",
   "name": "python3.7.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
